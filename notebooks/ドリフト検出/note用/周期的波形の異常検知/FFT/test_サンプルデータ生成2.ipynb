{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c4af3b",
   "metadata": {},
   "source": [
    "## Tennessee Eastman（TE/TEP）プロセスのサンプルデータ\n",
    "\n",
    "変数多いが手間がかかる\n",
    "\n",
    "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi%3A10.7910%2FDVN%2F6C3JR1&utm_source=chatgpt.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8561be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdata\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================\n",
    "# TE（Harvard Dataverse版: .RData）読み込み（画像のコード準拠）\n",
    "# ============================================================\n",
    "\n",
    "DATA_DIR = Path(r\".\\TEPdata\")  # 例: r\"C:\\...\\TEP_harvard_raw\"\n",
    "FF_PATH  = DATA_DIR / \"TEP_FaultFree_Testing.RData\"\n",
    "FY_PATH  = DATA_DIR / \"TEP_Faulty_Testing.RData\"\n",
    "\n",
    "# ----------------------------\n",
    "# 1) RData を読み込み → dictへ変換\n",
    "# ----------------------------\n",
    "ff_parsed = rdata.parser.parse_file(str(FF_PATH))\n",
    "ff_conv   = rdata.conversion.convert(ff_parsed)\n",
    "\n",
    "fy_parsed = rdata.parser.parse_file(str(FY_PATH))\n",
    "fy_conv   = rdata.conversion.convert(fy_parsed)\n",
    "\n",
    "# キー確認（想定: 'fault_free_testing', 'faulty_testing'）\n",
    "print(\"FaultFree keys:\", list(ff_conv.keys()))\n",
    "print(\"Faulty   keys:\", list(fy_conv.keys()))\n",
    "\n",
    "if \"fault_free_testing\" not in ff_conv:\n",
    "    raise KeyError(f\"'fault_free_testing' が見つかりません: {list(ff_conv.keys())}\")\n",
    "if \"faulty_testing\" not in fy_conv:\n",
    "    raise KeyError(f\"'faulty_testing' が見つかりません: {list(fy_conv.keys())}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2) DataFrame化（画像のコードと同じ）\n",
    "# ----------------------------\n",
    "ff_df = pd.DataFrame(ff_conv[\"fault_free_testing\"])\n",
    "fy_df = pd.DataFrame(fy_conv[\"faulty_testing\"])\n",
    "\n",
    "# faultNumber列名の揺れ対策（faultNumber / faultnumber 等）\n",
    "fault_col = next((c for c in fy_df.columns if c.lower() == \"faultnumber\"), None)\n",
    "if fault_col is None:\n",
    "    raise KeyError(f\"'faultNumber' 列が見つかりません: {list(fy_df.columns)[:30]} ...\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3) 画像のスライス規則で「正常」「チューニング」「故障ごと」を作る\n",
    "#    ・行: 0:960 を1本ぶんの長さとして利用\n",
    "#    ・列: 3: で先頭3列（メタ列）を落とす\n",
    "# ----------------------------\n",
    "normal_data = ff_df.iloc[0:960, 3:].reset_index(drop=True)       # 学習用データ（正常）\n",
    "tuning_data = ff_df.iloc[960:1920, 3:].reset_index(drop=True)    # チューニング用（正常）\n",
    "\n",
    "# 故障データ（faultNumber==i を取り、先頭960行・列3: だけ）\n",
    "fault_data_dict = {}\n",
    "for i in range(1, 21):  # 画像のコード準拠（1..20）\n",
    "    idv = fy_df[fy_df[fault_col].astype(int) == i].iloc[0:960, 3:].reset_index(drop=True)\n",
    "    fault_data_dict[i] = idv\n",
    "\n",
    "print(\"normal_data:\", normal_data.shape)\n",
    "print(\"tuning_data:\", tuning_data.shape)\n",
    "print(\"fault 14    :\", fault_data_dict[14].shape)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) CSVに保存（必要なら：画像のコード準拠）\n",
    "# ----------------------------\n",
    "OUT_DIR = DATA_DIR / \"csv_out\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "normal_data.to_csv(OUT_DIR / \"normal-data.csv\", index=False)\n",
    "tuning_data.to_csv(OUT_DIR / \"tuning-data.csv\", index=False)\n",
    "\n",
    "for i, df_i in fault_data_dict.items():\n",
    "    df_i.to_csv(OUT_DIR / f\"idv_str{i}_data.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
